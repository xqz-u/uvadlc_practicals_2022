#!/bin/bash

#SBATCH --partition=gpu_shared_course
#SBATCH --gres=gpu:1
#SBATCH --job-name=TrainAAE
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=3
#SBATCH --time=00:30:00
#SBATCH --mem=12G
#SBATCH --output=/home/%u/job_logs/%x_%A_%a_%u.out
#SBATCH --array=0,2

z_dims=(8 2)
ae_lambda=("--lambda_ 1.0")
logs_dirs=("AE_logs")

i=$SLURM_ARRAY_TASK_ID

z_dim=${z_dims[$(($SLURM_ARRAY_TASK_ID / 2))]}
ae_flag=${ae_lambda[$(($SLURM_ARRAY_TASK_ID % 2))]}
logs_dir=${logs_dirs[$(($SLURM_ARRAY_TASK_ID % 2))]}

module purge
module load 2021
module load Anaconda3/2021.05

# Activate your environment
source activate dl2022

# Run your code
code_dir="$HOME/uvadlc_practicals_2022/assignment3/part2"
time srun python -u $code_dir/train.py \
     --data_dir /scratch/$USER/ \
     --log_dir $code_dir/$logs_dir"_"$z_dim \
     --ae_lr 1e-4 \
     --num_workers 3 \
     --z_dim $z_dim \
     $ae_flag
